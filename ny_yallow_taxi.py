# -*- coding: utf-8 -*-
"""NY Yallow Taxi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y30gaW_wjiaWT1wIW6hNYFxUIhHafKCx
"""

import pandas as pd
import numpy as np
import matplotlib as plt
import seaborn as sns
import datetime as dt


df = pd.read_csv("2017_Yellow_Taxi_Trip_Data.csv")

df.size

df.shape

df.columns

df.head(10)

df.info()

df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'], format='mixed')

df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'], format='mixed')

df['pickup date'] = df['tpep_pickup_datetime'].dt.strftime('%d-%b-%Y')

df['pickup time'] = df['tpep_pickup_datetime'].dt.strftime('%H:%M:%S')

df['dropoff time'] = df['tpep_dropoff_datetime'].dt.strftime('%H:%M:%S')

df['trip duration'] = df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']

df['trip duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60

df['trip duration'] = round(df['trip duration'], 0)

df.describe()

# Identify the record
mask = df['orderID'] == 93542707

# Swap the underlying datetime columns
df.loc[mask, ['tpep_pickup_datetime', 'tpep_dropoff_datetime']] = df.loc[mask, ['tpep_dropoff_datetime', 'tpep_pickup_datetime']].values

# Recalculate derived columns for consistency
df.loc[mask, 'trip duration'] = (df.loc[mask, 'tpep_dropoff_datetime'] - df.loc[mask, 'tpep_pickup_datetime']).dt.total_seconds() / 60
df.loc[mask, 'trip duration'] = round(df.loc[mask, 'trip duration'], 0)
df.loc[mask, 'pickup time'] = df.loc[mask, 'tpep_pickup_datetime'].dt.strftime('%H:%M:%S')
df.loc[mask, 'dropoff time'] = df.loc[mask, 'tpep_dropoff_datetime'].dt.strftime('%H:%M:%S')
df.loc[mask, 'pickup date'] = df.loc[mask, 'tpep_pickup_datetime'].dt.strftime('%d-%b-%Y')

# Verify the change
display(df[mask][['orderID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'trip duration']])

distance_analomy = df[(df['trip_distance'] <= 0) & (df['trip duration'] <= 0) & (df['total_amount'] <= 0)]
display(distance_analomy)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 5))
sns.boxplot(x=df['trip_distance'])
plt.title('Box Plot of Trip Distance')
plt.xlabel('Trip Distance (miles)')
plt.show()



import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(df['trip_distance'], bins=50, kde=True)
plt.title('Histogram of Trip Distance')
plt.xlabel('Trip Distance (miles)')
plt.ylabel('Frequency')
plt.show()



import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 5))
sns.boxplot(x=df['total_amount'])
plt.title('Box Plot of Total Amount')
plt.xlabel('Total Amount ($)')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(df['total_amount'], bins=100, kde=True)
plt.title('Histogram of Total Amount')
plt.xlabel('Total Amount ($)')
plt.ylabel('Frequency')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 6))
sns.histplot(data=df, x='tip_amount', hue='VendorID', bins=50, kde=True, palette='viridis')
plt.title('Histogram of Tip Amount by Vendor')
plt.xlabel('Tip Amount ($)')
plt.ylabel('Frequency')
plt.show()

import pandas as pd
import numpy as np

total_passenger = np.sum(df['passenger_count'])
total_passenger

passenger_unique = df['passenger_count'].unique()
passenger_unique

# Calculate mean tips by passenger_count

mean_tips_gruops = df.groupby('passenger_count')['tip_amount'].mean()
mean_tips_gruops

# Create bar plot for mean tips by passenger count

mean_tips_gruops.plot(kind='bar', figsize=(10, 6))
plt.title('Mean Tips by Passenger Count')
plt.xlabel('Passenger Count')
plt.ylabel('Mean Tip Amount ($)')
plt.xticks(rotation=0)
plt.show()

df.head(10)

df['Month'] = df['tpep_pickup_datetime'].dt.strftime('%b')
df['Day'] = df['tpep_pickup_datetime'].dt.strftime('%a')
df['Year'] = df['tpep_pickup_datetime'].dt.strftime('%Y')

# Get total number of rides for each month
rides_by_month = df.groupby('Month').size()

# Reorder the monthly ride list so months go in order
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
rides_by_month = rides_by_month.reindex(month_order)

display(rides_by_month)

# plot total number of rides for each month

rides_by_month.plot(kind='bar', figsize=(10, 6))
plt.title('Total Number of Rides by Month')
plt.xlabel('Month')
plt.ylabel('Total Number of Rides')
plt.xticks(rotation=0)
plt.show()

# Get total number of passenger for each month
total_passenger_by_month = df.groupby('Month')['passenger_count'].sum()

# Reorder the monthly ride list so months go in order
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
total_passenger_by_month = total_passenger_by_month.reindex(month_order)

total_passenger_by_month

# plot total number of passenger for each month
total_passenger_by_month.plot(kind='bar', figsize=(10, 6))
plt.title('Total Number of Passenger by Month')
plt.xlabel('Month')
plt.ylabel('Total Number of Passenger')
plt.xticks(rotation=0)
plt.show()

# Get total number of rides for each Day
rides_by_day = df.groupby('Day').size()

# Reorder the monthly ride list so months go in order
day_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
rides_by_day = rides_by_day.reindex(day_order)

display(rides_by_day)

# plot total number of passenger for each Day
rides_by_day.plot(kind='bar', figsize=(10, 6))
plt.title('Total Number of Rides by Day')
plt.xlabel('Day')
plt.ylabel('Total Number of Rides')
plt.xticks(rotation=0)
plt.show()

# total revenue by day of the week
total_revenue_by_day = df.groupby('Day')['total_amount'].sum()

# Reorder the daily ride list so months go in order
day_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
total_revenue_by_day = total_revenue_by_day.reindex(day_order)

total_revenue_by_day

# plot total revenue by day of the week
total_revenue_by_day.plot(kind='bar', figsize=(10,6))
plt.title('Total Revenue by Day of the Week')
plt.xlabel('Day of the Week')
plt.ylabel('Total Revenue $')
plt.xticks(rotation=0)
plt.show()

# total revenue by month
total_revenue_by_month = df.groupby('Month')['total_amount'].sum()

# Reorder the monthly ride list so months go in order
month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Dec']
total_revenue_by_month = total_revenue_by_month.reindex(month_order)

total_revenue_by_month

# plot total revenue by month
total_revenue_by_month.plot(kind='bar', figsize=(10,6))
plt.title('Total Revenue by Month')
plt.xlabel('Month')
plt.ylabel('Total Revenue $')
plt.xticks(rotation=0)
plt.show()

# Get number of unique drop-off location IDs
unique_dropoff_ids = pd.Series(df['DOLocationID'].unique()).size

# Display the unique drop-off location IDs
unique_dropoff_ids

# Sort mean trip distances in ascending order
mean_trip_distance_ascending = mean_trip_distance_by_dropoff.sort_values(ascending=True)

# Create a bar plot
plt.figure(figsize=(20, 8))
mean_trip_distance_ascending.plot(kind='bar')
plt.title('Mean Trip Distance by Drop-off Location (Ascending)')
plt.xlabel('Drop-off Location ID')
plt.ylabel('Mean Trip Distance (miles)')
plt.xticks(rotation=90, fontsize=8)
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(mean_trip_distance_by_dropoff, bins=30, kde=True)
plt.title('Distribution of Mean Trip Distances by Drop-off Location')
plt.xlabel('Mean Trip Distance (miles)')
plt.ylabel('Frequency (Number of Locations)')
plt.show()



"""# Task
Simulate 1,500 start points and a set of unique endpoints using a normal distribution with a mean of 10 and a standard deviation of 5, calculate the Euclidean distance for each pair, determine the mean distance per unique endpoint, and visualize the results using a bar plot.

## Simulate Coordinate Data

### Subtask:
Generate 1,500 start points and a set of unique endpoints using a normal distribution.

**Reasoning**:
I will generate the simulated coordinate data by following the provided instructions, which include generating start and end points from a normal distribution and combining them into a pandas DataFrame.
"""

import numpy as np
import pandas as pd

# Set random seed for reproducibility
np.random.seed(42)

# 1. Generate 1,500 start points (x and y coordinates)
n_starts = 1500
mean, std = 10, 5
start_x = np.random.normal(mean, std, n_starts)
start_y = np.random.normal(mean, std, n_starts)

# 2. Define 10 unique endpoints with IDs
n_endpoints = 10
endpoint_ids = np.arange(1, n_endpoints + 1)
end_x_coords = np.random.normal(mean, std, n_endpoints)
end_y_coords = np.random.normal(mean, std, n_endpoints)

# Store endpoints in a temporary lookup table/DataFrame
endpoints_lookup = pd.DataFrame({
    'endpoint_id': endpoint_ids,
    'end_x': end_x_coords,
    'end_y': end_y_coords
})

# 3. Randomly assign one of the 10 endpoints to each of the 1,500 start points
assigned_indices = np.random.choice(n_endpoints, size=n_starts)
assigned_endpoints = endpoints_lookup.iloc[assigned_indices].reset_index(drop=True)

# 4. Combine into a final DataFrame
simulated_coords_df = pd.DataFrame({
    'start_x': start_x,
    'start_y': start_y
})
simulated_coords_df = pd.concat([simulated_coords_df, assigned_endpoints], axis=1)

# Display the first few rows
print(f'DataFrame shape: {simulated_coords_df.shape}')
simulated_coords_df.head()

"""## Calculate Euclidean Distance

### Subtask:
Calculate the Euclidean distance for each start-end point pair and add it to the DataFrame.

**Reasoning**:
I will calculate the Euclidean distance between `(start_x, start_y)` and `(end_x, end_y)` using the distance formula: $\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$. This will be added as a new column to the `simulated_coords_df` DataFrame.

**Reasoning**:
Calculate the Euclidean distance for each start-end point pair using the formula and add it as a new column to the `simulated_coords_df` DataFrame.
"""

# Calculate the Euclidean distance for each pair
simulated_coords_df['euclidean_distance'] = np.sqrt(
    (simulated_coords_df['end_x'] - simulated_coords_df['start_x'])**2 +
    (simulated_coords_df['end_y'] - simulated_coords_df['start_y'])**2
)

# Display the first few rows to verify the calculation
simulated_coords_df.head()

from google.colab import files

# Save the cleaned taxi dataframe to an Excel file
# Note: This requires the 'openpyxl' library which is standard in Colab
file_name = 'cleaned_taxi_data.xlsx'
df.to_excel(file_name, index=False)

# Download the file
files.download(file_name)

"""## Determine Mean Distance per Unique Endpoint

### Subtask:
Calculate the mean Euclidean distance for each of the 10 unique endpoints.

**Reasoning**:
I will group the `simulated_coords_df` by the `endpoint_id` and compute the average of the `euclidean_distance` column to see which endpoints are, on average, furthest from the start points.

**Reasoning**:
With the Euclidean distances calculated, I will now group the data by 'endpoint_id' and calculate the mean 'euclidean_distance' for each unique endpoint to satisfy the next part of the task.
"""

# Calculate the mean Euclidean distance for each unique endpoint
mean_distance_per_endpoint = simulated_coords_df.groupby('endpoint_id')['euclidean_distance'].mean()

# Display the mean distances
print("Mean Euclidean Distance per Endpoint ID:")
print(mean_distance_per_endpoint)

"""## Visualize Mean Distances

### Subtask:
Create a bar plot to visualize the mean Euclidean distance for each unique endpoint ID.

**Reasoning**:
I will use a bar plot to display the calculated mean distances for each `endpoint_id`. This visualization will help identify which endpoints are, on average, located furthest or closest to the generated start points.

**Reasoning**:
I will create a bar plot using matplotlib to visualize the mean Euclidean distance for each unique endpoint ID, allowing for a clear comparison of how the average distance varies across different endpoints.
"""

import matplotlib.pyplot as plt

# Create a bar plot for the mean Euclidean distances
plt.figure(figsize=(10, 6))
mean_distance_per_endpoint.plot(kind='bar', color='teal', edgecolor='black')

# Adding titles and labels
plt.title('Mean Euclidean Distance per Unique Endpoint ID', fontsize=14)
plt.xlabel('Endpoint ID', fontsize=12)
plt.ylabel('Mean Euclidean Distance', fontsize=12)
plt.xticks(rotation=0)
plt.grid(axis='y', linestyle='--', alpha=0.7)

# Show the plot
plt.show()

"""## Summary:

### Q&A
**What were the results of the distance calculations between the 1,500 start points and the 10 unique endpoints?**
The simulation showed that mean Euclidean distances varied notably across different endpoints. While start points were generated around a mean of 10, the specific locations of the 10 endpoints resulted in average distances ranging from a minimum of approximately 6.74 units to a maximum of approximately 16.46 units.

### Data Analysis Key Findings
*   **Dataset Composition:** The analysis successfully processed 1,500 coordinate pairs (start points) randomly assigned to 10 unique fixed endpoints.
*   **Distance Variation:** Despite start and end points being drawn from the same normal distribution ($\mu=10, \sigma=5$), the mean distance per endpoint was not uniform.
*   **Maximum and Minimum Proximity:**
    *   **Endpoint 8** recorded the highest mean Euclidean distance at approximately 16.46 units.
    *   **Endpoint 10** recorded the lowest mean Euclidean distance at approximately 6.74 units.
*   **Visualization Trends:** The bar plot illustrated a clear disparity in spatial centralities, showing that some endpoints were naturally more "central" to the cloud of 1,500 start points than others due to random sampling.

### Insights or Next Steps
*   The significant range in mean distances (approx. 10 units difference between the best and worst cases) suggests that the specific location of a fixed "hub" or endpoint drastically affects efficiency, even in a normally distributed environment.
*   A valuable next step would be to perform a cluster analysis or create a scatter plot overlaying start points and endpoints to visually identify why specific IDs, like Endpoint 10, achieved much lower mean distances.

"""